{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73Fikdeb5L00",
        "outputId": "4b3510a2-b260-4f6e-cca8-2fcbf12537a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.1.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.3.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.22.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.7.0.72)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.20.3)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.6)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QKs1fwk69km-"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import imutils\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "import skimage.exposure\n",
        "from skimage import io\n",
        "import os\n",
        "from scipy.spatial import distance as dist\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils import perspective\n",
        "from imutils import contours\n",
        "from scipy.spatial import distance as dist\n",
        "import mediapipe as mp\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "w0mUq3jd3Uay"
      },
      "outputs": [],
      "source": [
        "draw_line = mp.solutions.drawing_utils\n",
        "mp_pose = mp.solutions.pose\n",
        "pose_est = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
        "\n",
        "\n",
        "def create_dir(file_path) :\n",
        "    if not os.path.exists(file_path):\n",
        "        os.makedirs(file_path)\n",
        "\n",
        "def generate_Mask(img) :\n",
        "    lab = cv2.cvtColor(img,cv2.COLOR_BGR2LAB) ##covert ke mode warna LAB\n",
        "    a_channel = lab[:,:,1] ##mengambil saluran warna citra merah-hijau\n",
        "    thresh = cv2.threshold(a_channel, 0,255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1] #ambang batas bawah 127 ambang atas 255\n",
        "                                                                                    # menghasilkan ambang biner adaptif\n",
        "    mask = cv2.bitwise_and(img, img, mask = thresh) #nilai pixel yang memiliki nilai 255 dipertahankan, yg tidak akan dihitamkan\n",
        "    mask_lab= cv2.cvtColor(mask, cv2.COLOR_BGR2LAB) #convert masked ke mode warna LAB\n",
        "    masked_img = cv2.cvtColor(mask_lab, cv2.COLOR_LAB2BGR) ##convert mask_lab ke warna RGB\n",
        "    masked_img[thresh==0]=(0,0,0) ##background diganti warna hitam\n",
        "    create_dir(\"masked_img\") ##buat directory\n",
        "    mask_path = os.path.join(\"masked_img\",\"masked_img.png\") #simpan foto di folder directory\n",
        "    cv2.imwrite(mask_path, masked_img)\n",
        "    return masked_img\n",
        "\n",
        "\n",
        "def find_Face(masked_img):\n",
        "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_alt2.xml\")\n",
        "    faces = faceCascade.detectMultiScale(\n",
        "        masked_img,\n",
        "        scaleFactor=1.1,\n",
        "        minNeighbors=3,\n",
        "        minSize=(30, 30)\n",
        "    )\n",
        "\n",
        "    if len(faces) == 0:\n",
        "        print (\"Face not found\")\n",
        "        return 0\n",
        "    else:\n",
        "        min_area = 0\n",
        "        for (x, y, w, h) in faces:\n",
        "            face_area = w*h\n",
        "            if face_area > min_area:\n",
        "                face = [x,y,w,h]\n",
        "        return face\n",
        "\n",
        "\n",
        "def get_Edged(masked_img) :\n",
        "    edged = cv2.Canny(masked_img, 50, 100) ##deteksi tepian gambar\n",
        "    edged = cv2.dilate(edged, None, iterations=1) ##memperluas dan mempertajam deteksi tepi (operasi dilasi)\n",
        "    edged = cv2.erode(edged, None, iterations=1)\n",
        "    return edged\n",
        "\n",
        "\n",
        "def get_Contour(masked_img):\n",
        "    edged = get_Edged(masked_img)\n",
        "    c = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # cari countour menggunakan edged\n",
        "    c = imutils.grab_contours(c)\n",
        "    (cnts, _) = contours.sort_contours(c) #mencari countour terbesar\n",
        "    lst_count=[]\n",
        "    for index,contour in enumerate(cnts):\n",
        "        lst_count.append([index,cv2.contourArea(contour)])\n",
        "    lst_count.sort(key=lambda lst_count: lst_count[1], reverse=True)\n",
        "    cnts = cnts[lst_count[0][0]]\n",
        "    return cnts, lst_count\n",
        "\n",
        "\n",
        "def midpoint(fromP, toP):\n",
        "\treturn ((fromP[0] + toP[0]) * 0.5, (fromP[1] + toP[1]) * 0.5)\n",
        "\n",
        "\n",
        "def get_Sckeleton(img,masked_img):\n",
        "    cnts, list = get_Contour(masked_img)#edged = get_Edged(masked_img)\n",
        "    imgc = img.copy()\n",
        "    box = cv2.minAreaRect(cnts) ##deteksi kotak terkecil yang melingkupi kontur\n",
        "    x, y, w, h = cv2.boundingRect(cnts) ##get bounding box melingkupi kontur\n",
        "    cv2.rectangle(imgc, (x, y), (x+w, y+h), (0, 0, 255), 3) ##return titik sudut rectangle\n",
        "    box = cv2.boxPoints(box)\n",
        "    box = np.array(box, dtype=\"int\")\n",
        "    box = imutils.perspective.order_points(box) ##mengurutkan titiksudut dari kiri,kanan\n",
        "    cv2.drawContours(imgc, [box.astype(\"int\")], -1, (0, 255, 0), 3)\n",
        "\n",
        "    for (x, y) in box:\n",
        "        cv2.circle(imgc, (int(x), int(y)), 5, (0, 0, 255), -1)\n",
        "\n",
        "    (TL, TR, BR, BL) = box\n",
        "    (TLTRx, TLTRy) = midpoint(TL, TR)\n",
        "    (BLBRx, BLBRy) = midpoint(BL, BR)\n",
        "    (TLBLx, TLBLy) = midpoint(TL, BL)\n",
        "    (TRBRx, TRBRy) = midpoint(TR, BR)\n",
        "\n",
        "    cv2.circle(imgc, (int(TLTRx), int(TLTRy)), 5, (255, 0, 0), -1)\n",
        "    cv2.circle(imgc, (int(BLBRx), int(BLBRy)), 5, (255, 0, 0), -1)\n",
        "    cv2.circle(imgc, (int(TLBLx), int(TLBLy)), 5, (255, 0, 0), -1)\n",
        "    cv2.circle(imgc, (int(TRBRx), int(TRBRy)), 5, (255, 0, 0), -1)\n",
        "\n",
        "    cv2.line(imgc, (int(TLTRx), int(TLTRy)), (int(BLBRx), int(BLBRy)),(255, 0, 255), 2)\n",
        "    cv2.line(imgc, (int(TLBLx), int(TLBLy)), (int(TRBRx), int(TRBRy)),(255, 0, 255), 2)\n",
        "    # plt.subplot(1,3,3)\n",
        "    # plt.imshow(imgc)\n",
        "    return imgc, box\n",
        "\n",
        "def get_Measurement(img, height) :\n",
        "    try :\n",
        "        img_ok = img.copy()\n",
        "        masked_img = generate_Mask(img)\n",
        "        face = find_Face(masked_img)\n",
        "        contour,list_c = get_Contour(masked_img)\n",
        "        x,y,w,h = cv2.boundingRect(contour)\n",
        "\n",
        "        box = [[x,y],[x, y+h],[x+w,y+h],[x+w,y]]\n",
        "        x,y,w,h = face    ##create face point\n",
        "        cv2.rectangle(img_ok,(x,y),(x+w,y+h),(0,0,250),2)\n",
        "        face_points_box = [[x,y],[x, y+h],[x+w,y+h],[x+w,y]]\n",
        "        face = np.array(face_points_box,dtype=int)\n",
        "        (TL, BL, BR, TR) = box\n",
        "        (TRx,TRy) = TR\n",
        "        (BRx,BRy) = BR\n",
        "        (TLx,TLy) = TL\n",
        "        (BLx,BLy) = BL\n",
        "        (TLTRx, TLTRy) = midpoint(TL, TR)\n",
        "        (BLBRx, BLBRy) = midpoint(BL, BR)\n",
        "        (TLBLx, TLBLy) = midpoint(TL,BL)\n",
        "        (TRBRx, TRBRy) = midpoint(TR,BR)\n",
        "\n",
        "    #estimasi tinggi dan lebar\n",
        "        est_h = dist.euclidean ((TLTRx,TLTRy), (BLBRx, BLBRy))\n",
        "        est_w = dist.euclidean ((TLBLx, TLBLy), (TRBRx, TRBRy))\n",
        "        est_s = get_shoulder(img_ok)\n",
        "        est_hp = get_hip(img_ok)\n",
        "        est_px = pixel_per_met_md(img_ok,height)\n",
        "        pixelMetric = est_h/float(height)\n",
        "        final_h = est_h/pixelMetric\n",
        "        if pose_detect(img) != \"Invalid Image\" :\n",
        "            final_w = round(est_w/pixelMetric,1)\n",
        "            # final_s = round(est_s*est_px,1)\n",
        "            final_hp = round(est_hp*est_px,1)\n",
        "        # img_final = cv2.cvtColor(masked_img,cv2.COLOR_BGR2RGB)\n",
        "            return final_h, final_w, final_hp\n",
        "        else :\n",
        "            return None, None, None, None\n",
        "    except ValueError :\n",
        "        return None, None, None, None\n",
        "\n",
        "def pose_detect(img):\n",
        "    res = pose_est.process(img)\n",
        "    landmarks = res.pose_landmarks\n",
        "    annotated_image = img.copy()\n",
        "    draw_line.draw_landmarks(\n",
        "    annotated_image, res.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
        "    if (landmarks.landmark[mp.solutions.pose.PoseLandmark.LEFT_ANKLE].visibility > 0.01\n",
        "    and landmarks.landmark[mp.solutions.pose.PoseLandmark.RIGHT_ANKLE].visibility > 0.01):\n",
        "        return landmarks\n",
        "    else:\n",
        "        return(\"Invalid Image\")\n",
        "\n",
        "\n",
        "def get_hip(image) :\n",
        "    try :\n",
        "        landmark_est = pose_detect(image)\n",
        "        if landmark_est != 'Invalid Image' :\n",
        "            h,w, _ = image.shape\n",
        "            left_hip = (landmark_est.landmark[mp.solutions.pose.PoseLandmark.LEFT_HIP].x,\n",
        "              landmark_est.landmark[mp.solutions.pose.PoseLandmark.LEFT_HIP].y)\n",
        "            right_hip = (landmark_est.landmark[mp.solutions.pose.PoseLandmark.RIGHT_HIP].x,\n",
        "               landmark_est.landmark[mp.solutions.pose.PoseLandmark.RIGHT_HIP].y)\n",
        "            # x_left_hip = int(left_hip[0] * w)\n",
        "            # y_left_hip = int(left_hip[1] * h)\n",
        "            # x_right_hip = int(right_hip[0] * w)\n",
        "            # y_right_hip = int(right_hip[1] * h)\n",
        "            hip_est = math.sqrt((right_hip[0] - left_hip[0])**2 + (right_hip[1] - left_hip[1])**2)\n",
        "            return hip_est\n",
        "    except ValueError :\n",
        "        return 'Invalid Image'\n",
        "\n",
        "def get_shoulder(image) :\n",
        "    try :\n",
        "        landmark_est = pose_detect(image)\n",
        "        if landmark_est != 'Invalid Image' :\n",
        "            h,w, _ = image.shape\n",
        "            left_shoulder = (landmark_est.landmark[mp.solutions.pose.PoseLandmark.LEFT_SHOULDER].x,\n",
        "                 landmark_est.landmark[mp.solutions.pose.PoseLandmark.LEFT_SHOULDER].y)\n",
        "            right_shoulder = (landmark_est.landmark[mp.solutions.pose.PoseLandmark.RIGHT_SHOULDER].x,\n",
        "                  landmark_est.landmark[mp.solutions.pose.PoseLandmark.RIGHT_SHOULDER].y)\n",
        "            # x_left_shoulder = int(left_shoulder[0] * w)\n",
        "            # y_left_shoulder = int(left_shoulder[1] * h)\n",
        "            # x_right_shoulder = int(right_shoulder[0] * w)\n",
        "            # y_right_shoulder = int(right_shoulder[1] * h)\n",
        "            shoulder_est = shoulder_est = math.sqrt((right_shoulder[0] - left_shoulder[0])**2 + (right_shoulder[1] - left_shoulder[1])**2)\n",
        "            return shoulder_est\n",
        "    except ValueError :\n",
        "        return 'Invalid Image'\n",
        "\n",
        "def pixel_per_met_md(img,h) :\n",
        "    try :\n",
        "        landmark_est= pose_detect(img)\n",
        "        if landmark_est != 'Invalid Image' :\n",
        "            point0 = landmark_est.landmark[mp.solutions.pose.PoseLandmark.NOSE]\n",
        "            point28 = landmark_est.landmark[mp.solutions.pose.PoseLandmark.RIGHT_ANKLE]\n",
        "            length = ((point0.x - point28.x) ** 2 + (point0.y - point28.y) ** 2) ** 0.5\n",
        "            px = h/length\n",
        "            return px\n",
        "    except ValueError :\n",
        "        return 'Invalid Image'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://storage.googleapis.com/modelproject20793/normalized_dataset.csv')"
      ],
      "metadata": {
        "id": "3siOKOF4bsp_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_data = df['Size'].values"
      ],
      "metadata": {
        "id": "M-rnSDI4cQAC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "f = urllib.request.urlopen('https://storage.googleapis.com/modelproject20793/model.pkl')\n",
        "model = pickle.load(f)"
      ],
      "metadata": {
        "id": "5h1tXWp8cRv_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.model_from_json(model)\n",
        "label_encoder = LabelEncoder()\n",
        "output_data = label_encoder.fit_transform(output_data)"
      ],
      "metadata": {
        "id": "rhFMqUpZcWeg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_size(data):\n",
        "    data = np.array(data)\n",
        "    data = np.reshape(data, (1, data.shape[0]))\n",
        "    pred = model.predict(data)\n",
        "    predicted_labels = np.argmax(pred, axis=1)\n",
        "    predicted_sizes = label_encoder.inverse_transform(predicted_labels)\n",
        "    return predicted_sizes"
      ],
      "metadata": {
        "id": "9Nr5hOXQcZZY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = io.imread('https://storage.googleapis.com/abji/dataset2.jpg')\n",
        "cv2.imwrite(\"new_image.jpg\", image)\n",
        "img = cv2.imread(\"new_image.jpg\")\n",
        "\n",
        "h,s,hp = get_Measurement(img, 180)\n",
        "mask = generate_Mask(img)\n",
        "imgc, box = get_Sckeleton(img,mask)\n",
        "input_data = [21, s, hp, h]\n",
        "print(\"estimation height : \",h)\n",
        "print(\"estimation shoulder-width : \",s)\n",
        "print(\"estimation hip-width : \",hp)\n",
        "print(pred_size(input_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJVlxHVZy3-6",
        "outputId": "11262849-07c8-4ff1-cb10-2da4156bcea6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "estimation height :  180.0\n",
            "estimation shoulder-width :  56.7\n",
            "estimation hip-width :  32.6\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "['XL']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}